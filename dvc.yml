stages:
  scrape:
    cmd: |
      pip install -r services/scraper/requirements.txt &&
      playwright install --with-deps chromium &&
      python services/scraper/cli.py --title_per_page 10 --max_pages 100
    deps:
      - services/scraper/cli.py
      - services/scraper/scraping.py
      - services/scraper/requirements.txt
    outs:
      - data/raw/mit_scraped_1000.json

  preprocess:
    cmd: |
      pip install -r services/preprocessor/requirements.txt &&
      python services/preprocessor/cli.py
    deps:
      - services/preprocessor/cli.py
      - services/preprocessor/preprocessing.py
      - services/preprocessor/requirements.txt
      - data/raw/mit_scraped_1000.json
    outs:
      - data/processed/data_preprocessed.json
      - data/processed/embeddings.npy

  train:
    cmd: |
      pip install -r services/trainer/requirements.txt &&
      python services/trainer/cli.py
    deps:
      - services/trainer/cli.py
      - services/trainer/bert.py
      - services/trainer/requirements.txt
      - data/processed/data_preprocessed.json
      - data/processed/embeddings.npy
    outs:
      - models/topic_model.pkl
