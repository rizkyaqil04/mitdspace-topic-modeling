stages:
  scrape:
    cmd: |
      pip install -r services/scraper/requirements.txt 
      playwright install --with-deps chromium 
      python services/scraper/main.py --title_per_page 10 --max_pages 100
    deps:
      - services/scraper/main.py
      - services/scraper/scraping.py
      - services/scraper/requirements.txt
    outs:
      - data/raw/mit_scraped_1000.json

  preprocess:
    cmd: |
      pip install -r services/preprocessor/requirements.txt 
      python services/preprocessor/main.py
    deps:
      - services/preprocessor/main.py
      - services/preprocessor/preprocessing.py
      - services/preprocessor/requirements.txt
      - data/raw/mit_scraped_1000.json
    outs:
      - data/processed/data_preprocessed.json
      - data/processed/embeddings.npy

  train:
    cmd: |
      pip install -r services/trainer/requirements.txt 
      python services/trainer/main.py
    deps:
      - services/trainer/main.py
      - services/trainer/bert.py
      - services/trainer/requirements.txt
      - data/processed/data_preprocessed.json
      - data/processed/embeddings.npy
    outs:
      - runs/topic_model
